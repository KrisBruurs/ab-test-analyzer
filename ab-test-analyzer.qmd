---
title: "ab-test-analyzer"
author: "Kris Bruurs"
format: html
editor: visual
---

# A/B Test Analyzer

## 0. Contents

-   1\. Introduction
-   2\. Data Handling
    -   2.1. Data Preperation
    -   2.2 Data Exploration
-   3\. Hypothesis Testing
    -   3.1 **H1:** Purchases ÷ Impressions (purchase conversion rate)
        -   3.1.1 Code
        -   3.1.2 Report
    -   3.2 **H2:** Reach ÷ Impressions (unique reach ratio)
        -   3.2.1 Code
        -   3.2.2 Report
    -   3.3 **H3:** Purchases ÷ Add to Cart (checkout conversion)
        -   3.3.1 Code
        -   3.3.2 Report
    -   3.4 **H4:** Searches/View Content/Add to Cart ÷ Impressions (upper/mid-funnel rates)
        -   3.4.1 Code
        -   3.4.2 Report
-   4\. Final Report

## 1. Introduction

The dataset shows the results of a 30 day A/B test for a fictional company's website. The outputs are the following variables:

-   **Campaign Name:** Name of the campaign version (*Control / Test*)
-   **Date:** Date of the record
-   **Spend:** Amount spend on the campaign in USD
-   **Number of Impressions:** Number of impressions the ad crossed through the campaign
-   **Reach:** The number of unique impressions received on the ad
-   **Number of Website Clicks:** Number of website clicks received through the ad
-   **Number of Searches:** Number of users who performed searches on the website
-   **Number of View Content:** Number of users who viewed products and content on the website
-   **Number of Add to Cart:** Number of users who added products to the cart
-   **Number of Purchase:** Number of purchases

The data shows no **Average Spend per Purchase** variable. Therefore a complete analysis of campaign effectiveness gets harder. Metrics such as ROAS or ROI are impossible to measure with the available data.

However, the data allows for an analysis of engagement. Questions that can be answered are:

1.  **Does the test campaign convert more impressions into purchases than the control campaign?**
    -   *H1:* The test campaign convert more impressions into purchases than the control campaign.
2.  **Does the test campaign have more impressions from unique users than the control campaign?**
    -   *H2:* The test campaign has more impressions from unique users than the control campaign.
3.  **Does the test campaign convert more 'add to carts' into purchases than the control campaign?**
    -   *H3:* The test campaign converts more 'add to carts' into purchases than the control campaign.
4.  **Does the test campaign have a lower cost per purchase than the control campaign?**
    -   *H4:* The test campaign has a lower cost per purchase than the control campaign.

## 2. Data Handling

### 2.1 Data Preparation

#### Load Libraries

```{r}
#| message: FALSE
library(tidyverse)
```

#### Load Data

```{r}
#| message: FALSE
control <- read_delim('data/control_group.csv', delim = ';')
test <- read_delim('data/test_group.csv', delim = ';')

```

#### Merge Data

Merge two files together:

```{r}
combined_data <- control %>% 
  bind_rows(test)
```

#### Rename Variables

```{r}
combined_data <- combined_data %>% 
  rename(Campaign_Name = `Campaign Name`,
         Spend = `Spend [USD]`,
         Impressions = `# of Impressions`,
         Clicks = `# of Website Clicks`,
         Searches = `# of Searches`,
         View_Content = `# of View Content`,
         Add_Cart = `# of Add to Cart`,
         Purchase = `# of Purchase`)
```

#### Data Cleaning

Check the data for NA's:

```{r}
anyNA(combined_data)
```

This shows that there are NA's present in the data. As the data has 60 rows, a manual inspection of the data is executed.

This inspection of the data shows that one day in the control campaign has not collected data except for costs. Therefore, this row is removed

```{r}
#| message: false
combined_data <- combined_data %>%
  filter(!(is.na(Impressions) & is.na(Clicks) & is.na(Searches) &
           is.na(View_Content) & is.na(Add_Cart) & is.na(Purchase)))
```

### 2.2 Data Exploration

```{r}
combined_data %>% 
  ggplot(aes(x = Campaign_Name, y = Spend, fill = Campaign_Name)) +
  geom_col() +
  labs(y = 'Spend in USD',
       x = NULL,
       fill = "Campaign Version",
       title = 'Spenditure Between Campaign Versions') +
  theme(axis.text.x = element_blank())
  
```

```{r}
#| message: false
mean_spend_control <- combined_data %>% 
  group_by(Campaign_Name) %>% 
  summarize(mean_spend = mean(Spend)) %>% 
  pluck(2,1)

mean_spend_test <- combined_data %>% 
  group_by(Campaign_Name) %>% 
  summarize(mean_spend = mean(Spend)) %>% 
  pluck(2,2)

avg_spend_diff <- mean_spend_test - mean_spend_control
final_spend_diff = round(avg_spend_diff, 2)
```

The Test Campaign is on average about \$`r final_spend_diff` dollar more expensive per day than the Control Campaign.

## 3. Hypothesis Testing

```{r}
totals <- combined_data %>% 
  group_by(Campaign_Name) %>% 
  summarise(sum_impressions = sum(Impressions),
            sum_purchase = sum(Purchase),
            sum_reach = sum(Reach),
            sum_add_cart = sum(Add_Cart),
            sum_clicks = sum(Clicks),
            sum_view_content = sum(View_Content),
            sum_searches = sum(Searches),
            sum_spend = sum(Spend))
totals
```

### 3.1 H1 Impressions — Purchases

*H1:* The test campaign convert more impressions into purchases than the control campaign.

#### Code

```{r}
prop.test(x = totals$sum_purchase, 
          n = totals$sum_impressions,
          alternative = 'two.sided')
```

#### Report

To test whether the test campaign converted more impressions into purchases than the control campaign, a chi-square test of equal proportions showed that the purchase rate differed significantly between control group (.48%) and the test group (.70%), χ²(1, N = *total impressions*) = 1140.40, p \< .001. The difference in proportions was −0.0022, 95% CI \[−0.00235, −0.00208\].

The test campaign achieved a significantly higher conversion rate than the control campaign, supporting the hypothesis that the test campaign generates more purchases per impression.

### 3.2 H2 Impressions — Reach

*H2:* The test campaign has more impressions from unique users than the control campaign.

#### Code

```{r}
prop.test(x = totals$sum_reach,
          n = totals$sum_impressions,
          alternative = 'two.sided')
```

#### Report

To test whether the test campaign has more impressions from unique users than the control campaign, a chi-square test of equal proportions showed that the proportions of impressions coming from unique users differed significantly between the control campaign (81,1%) and the test campaign (71,7%), χ²(1, N = *total impressions*) = 65,577, p \< .001. The difference in proportions was 0.094, 95% CI \[0.093, 0.094\].

The control campaign had a significantly higher proportion of impressions from unique users than the test campaign, contrary to the hypothesis that the test campaign would generate more unique-user impressions.

### 3.3 H3 Add to Carts — Purchases

*H3:* The test campaign converts more 'add to carts' into purchases than the control campaign.

#### Code

```{r}
prop.test(x = totals$sum_purchase,
          n = totals$sum_add_cart,
          alternative = 'two.sided')
```

#### Report

To test whether the test campaign converted more “add to carts” into purchases than the control campaign, a chi-square test of equal proportions showed that the conversion rate from add-to-carts to purchases differed significantly between the control version (40.2%) and the test version (59.1%), χ²(1, N = *total add-to-carts*) = 2226.70, p \< .001. The difference in proportions was −0.189, 95% CI \[−0.197, −0.181\].

The test campaign converted a significantly greater proportion of add-to-carts into purchases compared to the control campaign, supporting the hypothesis that the test campaign was more effective at driving purchases from add-to-carts.

### 3.4 H4 CPP — Advertisement Version

##### Codel

##### Report

## 4. Final Report
